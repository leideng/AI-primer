{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ6VyNLuuUSrEGcH3z8xzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leideng/AI-primer/blob/main/pytorch/tensor_slice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is a notebook about how to efficiently slide a pytorch tensor in different manners\n",
        "\n",
        "## Python's slicing\n",
        "\n",
        "## Boolean index\n",
        "\n",
        "## Index"
      ],
      "metadata": {
        "id": "l2TwH_uGwZIH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c43vEdjOwUYd",
        "outputId": "58a0a9e4-949c-4d8c-d81f-257e63ac78ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=tensor([[-5,  3, -5, -2,  3, -4,  3,  1],\n",
            "        [-3,  3, -3,  4, -2,  1,  2, -4],\n",
            "        [-3,  0,  0,  1,  0, -2, -4, -3],\n",
            "        [ 0,  2, -3,  0,  1, -5,  3,  4],\n",
            "        [-4, -1,  1, -1, -5,  3,  3,  3]])\n",
            "row 1: x1=x[1,:]=tensor([-3,  3, -3,  4, -2,  1,  2, -4])\n",
            "x1.shape=torch.Size([8])\n",
            "column 1: y1=y[:,1]=tensor([ 3,  3,  0,  2, -1])\n",
            "y1.shape=torch.Size([5])\n",
            "x2_3=x[2,3]=1\n",
            "x2_3.shape=torch.Size([])\n",
            "x2_35=x[2,3:5]=tensor([1, 0])\n",
            "x2_35.shape=torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "# Python's slicing\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "x = torch.randint(low=-5, high=5, size=(5,8), device=device)\n",
        "print(f\"x={x}\")\n",
        "\n",
        "x1 = x[1,:]\n",
        "print(f\"row 1: x1=x[1,:]={x1}\")\n",
        "print(f\"x1.shape={x1.shape}\")\n",
        "\n",
        "y1 = x[:,1]\n",
        "print(f\"column 1: y1=y[:,1]={y1}\")\n",
        "print(f\"y1.shape={y1.shape}\")\n",
        "\n",
        "x2_3 = x[2,3]\n",
        "x2_35 = x[2,3:5]\n",
        "print(f\"x2_3=x[2,3]={x2_3}\")\n",
        "print(f\"x2_3.shape={x2_3.shape}\")\n",
        "print(f\"x2_35=x[2,3:5]={x2_35}\")\n",
        "print(f\"x2_35.shape={x2_35.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Boolean Index\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "x = torch.randint(low=1,high=100, size=(5,10), device=device)\n",
        "print(f\"x={x}\")\n",
        "print(f\"x.shape={x.shape}\")\n",
        "\n",
        "idx = (x >= 80)\n",
        "print(f\"idx=(x >= 80)={idx}\")\n",
        "print(f\"idx.shape={idx.shape}\")\n",
        "\n",
        "y = x[idx]\n",
        "print(f\"y={y}\")  #flattern to 1D tensor\n",
        "print(f\"y.shape={y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqRlSYw3ytBh",
        "outputId": "35c265f5-912c-4e7a-b9c3-52257c8973ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x=tensor([[44, 95, 71, 60, 23, 31, 36, 81, 68, 22],\n",
            "        [12,  9, 32, 64, 99, 66, 72, 49, 12, 16],\n",
            "        [10, 66, 10, 46, 60, 48, 46, 98, 35, 22],\n",
            "        [74,  1, 37, 43, 22, 84, 84, 13, 47, 29],\n",
            "        [86,  2, 12, 20, 32, 51, 61, 90, 34,  1]])\n",
            "x.shape=torch.Size([5, 10])\n",
            "idx=(x >= 80)=tensor([[False,  True, False, False, False, False, False,  True, False, False],\n",
            "        [False, False, False, False,  True, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False,  True, False, False],\n",
            "        [False, False, False, False, False,  True,  True, False, False, False],\n",
            "        [ True, False, False, False, False, False, False,  True, False, False]])\n",
            "idx.shape=torch.Size([5, 10])\n",
            "y=tensor([95, 81, 99, 98, 84, 84, 86, 90])\n",
            "y.shape=torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced Index\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Define the block_table tensor\n",
        "block_table = torch.tensor([[17, 0, 14, 12, 15, 29, 8, -1, -1, -1],\n",
        "                            [6, 24, 28, 22, 27, 25, -1, -1, -1, -1],\n",
        "                            [2, 4, 21, 1, 9, 11, 13, 3, 16, -1]], device=device)\n",
        "\n",
        "# Define the index tensor\n",
        "idx = torch.tensor([[0, 2, 5, 6, 9],\n",
        "                    [1, 2, 3, 4, 8],\n",
        "                    [0, 2, 3, 5, 7]])\n",
        "\n",
        "# Get the number of rows from block_table and the number of columns from idx\n",
        "num_rows = block_table.shape[0]\n",
        "num_cols_idx = idx.shape[1]\n",
        "\n",
        "# Create a row index tensor that broadcasts across the columns of idx\n",
        "# torch.arange(num_rows) creates [0, 1, 2]\n",
        "# .unsqueeze(1) changes it to [[0], [1], [2]]\n",
        "# .expand(-1, num_cols_idx) expands it to [[0,0,0,0,0], [1,1,1,1,1], [2,2,2,2,2]]\n",
        "row_indices = torch.arange(num_rows).unsqueeze(1).expand(-1, num_cols_idx)\n",
        "\n",
        "# Use advanced indexing to get the sliced tensor\n",
        "sliced_tensor = block_table[row_indices, idx]\n",
        "\n",
        "print(\"Original block_table:\")\n",
        "print(block_table)\n",
        "print(\"\\nRow idx:\")\n",
        "print(row_indices)\n",
        "print(\"\\nOriginal (cloumn) idx:\")\n",
        "print(idx)\n",
        "print(\"\\nSliced tensor:\")\n",
        "print(sliced_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxytT8DrzdA1",
        "outputId": "180b2e18-7c56-4e92-9b06-f58eba1db6f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original block_table:\n",
            "tensor([[17,  0, 14, 12, 15, 29,  8, -1, -1, -1],\n",
            "        [ 6, 24, 28, 22, 27, 25, -1, -1, -1, -1],\n",
            "        [ 2,  4, 21,  1,  9, 11, 13,  3, 16, -1]])\n",
            "\n",
            "Row idx:\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [2, 2, 2, 2, 2]])\n",
            "\n",
            "Original (cloumn) idx:\n",
            "tensor([[0, 2, 5, 6, 9],\n",
            "        [1, 2, 3, 4, 8],\n",
            "        [0, 2, 3, 5, 7]])\n",
            "\n",
            "Sliced tensor:\n",
            "tensor([[17, 14, 29,  8, -1],\n",
            "        [24, 28, 22, 27, -1],\n",
            "        [ 2, 21,  1, 11,  3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanatiopn**\n",
        "- `num_rows = block_table.shape[0]`: This gets the number of rows in your block_table (which is 3).\n",
        "- `num_cols_idx = idx.shape[1]`: This gets the number of columns in your idx tensor (which is 5).\n",
        "- `row_indices = torch.arange(num_rows)`: This creates a 1D tensor [0, 1, 2]. These are the row indices we want to select from block_table.\n",
        "- `.unsqueeze(1)`: This reshapes row_indices from [0, 1, 2] to [[0], [1], [2]]. This is crucial for broadcasting.\n",
        "- `.expand(-1, num_cols_idx)`: This expands the row_indices tensor to have the same shape as idx (3x5). The -1 means \"keep the size of this dimension as is\". So, [[0], [1], [2]] becomes [[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2]].\n",
        "- `block_table[row_indices, idx]`: This is the advanced indexing step. PyTorch takes corresponding elements from row_indices and idx to form (row, col) pairs for indexing.\n",
        "  - For the first row, it uses `(0, idx[0,0]), (0, idx[0,1]), ..., (0, idx[0,4])`.\n",
        "  - For the second row, it uses `(1, idx[1,0]), (1, idx[1,1]), ..., (1, idx[1,4])`.\n",
        "  - And so on.\n",
        "\n",
        "This method is efficient as it leverages PyTorch's optimized C++ backend for tensor operations."
      ],
      "metadata": {
        "id": "dFveToPpz7mF"
      }
    }
  ]
}